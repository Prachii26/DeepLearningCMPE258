{"cells":[{"cell_type":"markdown","metadata":{"id":"zEkrSo01WcC7"},"source":["# TensorFlow & Keras Advanced: Custom Layers and Deep Architectures\n","\n","## Part 2: Building Complex Operations from Scratch\n","\n","---\n","\n","In Part 1, we learned TensorFlow fundamentals, GradientTape basics, and the high-level Keras API. Now we go deeper!\n","\n","### What You'll Learn\n","\n","| Part | Topic | Key Concepts |\n","|------|-------|-------------|\n","| **I** | Advanced GradientTape | Nested tapes, Jacobians, custom gradients |\n","| **II** | Building Ops from Scratch | Convolution, pooling, normalization by hand |\n","| **III** | Custom Layers (Primitives) | Build layers using only tf.Variable |\n","| **IV** | Custom Keras Layers | Proper subclassing with `build()` and `call()` |\n","| **V** | Advanced Architectures | Residual blocks, attention, custom normalizations |\n","| **VI** | Custom Training Loops | Full control over training with GradientTape |\n","| **VII** | Practical Demos | Real-world examples with custom components |\n","\n","---\n","\n","*\"To understand the framework, build it from scratch.\"*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQaXbL0qWcC7","executionInfo":{"status":"ok","timestamp":1771138689377,"user_tz":480,"elapsed":19274,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"27986ce2-52aa-4481-c692-4a9f44d18dac"},"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow Version: 2.19.0\n","Keras Version:      3.10.0\n","GPU Available:      False\n","\n","Ready for Advanced TensorFlow & Keras!\n"]}],"source":["# ============================================================================\n","#                           SETUP & IMPORTS\n","# ============================================================================\n","\n","import tensorflow as tf\n","import keras\n","from keras import layers, Model, Sequential\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from typing import List, Tuple, Optional, Callable, Union\n","\n","# Beautiful plots\n","plt.style.use('seaborn-v0_8-whitegrid')\n","plt.rcParams['figure.figsize'] = (10, 6)\n","plt.rcParams['font.size'] = 12\n","\n","# Check versions\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","print(f\"Keras Version:      {keras.__version__}\")\n","print(f\"GPU Available:      {len(tf.config.list_physical_devices('GPU')) > 0}\")\n","\n","# GPU memory growth\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    for gpu in gpus:\n","        tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# Reproducibility\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","print(\"\\nReady for Advanced TensorFlow & Keras!\")"]},{"cell_type":"markdown","metadata":{"id":"0tItbO-4WcC8"},"source":["---\n","\n","# Part I: Advanced GradientTape Patterns\n","\n","## Beyond Basic Gradient Computation\n","\n","In Part 1, we used GradientTape for simple gradients. Now we'll explore:\n","\n","- **Nested tapes** for higher-order derivatives\n","- **Jacobian and Hessian** computation\n","- **Custom gradients** for non-differentiable operations\n","- **Gradient clipping** and manipulation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9-VhzBFWcC8","executionInfo":{"status":"ok","timestamp":1771138689487,"user_tz":480,"elapsed":117,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"3a7db6a6-2b6d-456e-bfce-b8815e40b997"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","       NESTED TAPES: HIGHER-ORDER DERIVATIVES\n","============================================================\n","\n","f(x) = x^4, evaluated at x = 2.0\n","\n","f(x)    = 16.0         (expected: 16)\n","f'(x)   = 32.0         (expected: 32 = 4*8)\n","f''(x)  = 48.0         (expected: 48 = 12*4)\n","f'''(x) = 48.0         (expected: 48 = 24*2)\n"]}],"source":["# ============================================================================\n","#                    NESTED GRADIENTTAPES: HIGHER-ORDER DERIVATIVES\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"       NESTED TAPES: HIGHER-ORDER DERIVATIVES\")\n","print(\"=\"*60)\n","\n","# Example: Compute first, second, and third derivatives\n","# f(x) = x^4\n","# f'(x) = 4x^3\n","# f''(x) = 12x^2\n","# f'''(x) = 24x\n","\n","x = tf.Variable(2.0)\n","\n","with tf.GradientTape() as tape3:\n","    with tf.GradientTape() as tape2:\n","        with tf.GradientTape() as tape1:\n","            y = x ** 4\n","        dy_dx = tape1.gradient(y, x)      # First derivative: 4x^3\n","    d2y_dx2 = tape2.gradient(dy_dx, x)    # Second derivative: 12x^2\n","d3y_dx3 = tape3.gradient(d2y_dx2, x)      # Third derivative: 24x\n","\n","print(f\"\\nf(x) = x^4, evaluated at x = {x.numpy()}\")\n","print(f\"\")\n","print(f\"f(x)    = {y.numpy():.1f}         (expected: 16)\")\n","print(f\"f'(x)   = {dy_dx.numpy():.1f}         (expected: 32 = 4*8)\")\n","print(f\"f''(x)  = {d2y_dx2.numpy():.1f}         (expected: 48 = 12*4)\")\n","print(f\"f'''(x) = {d3y_dx3.numpy():.1f}         (expected: 48 = 24*2)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdSJanpUWcC8","executionInfo":{"status":"ok","timestamp":1771138690118,"user_tz":480,"elapsed":629,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"9aceea23-d416-433b-9aa2-52e1aba89463"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","              JACOBIAN COMPUTATION\n","============================================================\n","\n","x = [1. 2. 3.]\n","y = f(x) = [x1^2, x1*x2, sin(x3)] = [1.      2.      0.14112]\n","\n","Jacobian (3x3):\n","[[ 2.         0.         0.       ]\n"," [ 2.         1.         0.       ]\n"," [ 0.         0.        -0.9899925]]\n","\n","Expected Jacobian:\n","  [2*x1,   0,      0   ]   = [2,   0,     0     ]\n","  [x2,     x1,     0   ]   = [2,   1,     0     ]\n","  [0,      0,  cos(x3) ]   = [0,   0,  -0.9900]\n"]}],"source":["# ============================================================================\n","#                    JACOBIAN COMPUTATION\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"              JACOBIAN COMPUTATION\")\n","print(\"=\"*60)\n","\n","# The Jacobian is the matrix of all first-order partial derivatives\n","# For f: R^n -> R^m, the Jacobian J is m x n where J[i,j] = df_i/dx_j\n","\n","x = tf.Variable([1.0, 2.0, 3.0])\n","\n","with tf.GradientTape() as tape:\n","    # Vector function: f(x) = [x1^2, x1*x2, sin(x3)]\n","    y = tf.stack([\n","        x[0] ** 2,\n","        x[0] * x[1],\n","        tf.sin(x[2])\n","    ])\n","\n","# Compute full Jacobian\n","jacobian = tape.jacobian(y, x)\n","\n","print(f\"\\nx = {x.numpy()}\")\n","print(f\"y = f(x) = [x1^2, x1*x2, sin(x3)] = {y.numpy()}\")\n","print(f\"\\nJacobian (3x3):\")\n","print(f\"{jacobian.numpy()}\")\n","\n","print(f\"\\nExpected Jacobian:\")\n","print(f\"  [2*x1,   0,      0   ]   = [2,   0,     0     ]\")\n","print(f\"  [x2,     x1,     0   ]   = [2,   1,     0     ]\")\n","print(f\"  [0,      0,  cos(x3) ]   = [0,   0,  {np.cos(3):.4f}]\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_a3dkRlWcC8","executionInfo":{"status":"ok","timestamp":1771138690613,"user_tz":480,"elapsed":491,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"c1b95a3c-d36e-460c-920b-2cccfbae67e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","              HESSIAN COMPUTATION\n","============================================================\n","\n","f(x, y) = x^2*y + y^3, at (x, y) = (1.0, 2.0)\n","f = 10.0\n","\n","Gradient: [ 4. 13.]\n","  Expected: [2xy, x^2 + 3y^2] = [4, 13]\n","\n","Hessian:\n","[[ 4.  2.]\n"," [ 2. 12.]]\n","  Expected:\n","  [2y,  2x ]   = [4, 2]\n","  [2x,  6y ]   = [2, 12]\n"]}],"source":["# ============================================================================\n","#                    HESSIAN COMPUTATION\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"              HESSIAN COMPUTATION\")\n","print(\"=\"*60)\n","\n","# The Hessian is the matrix of second-order partial derivatives\n","# H[i,j] = d^2f / (dx_i dx_j)\n","\n","x = tf.Variable([1.0, 2.0])\n","\n","with tf.GradientTape() as tape2:\n","    with tf.GradientTape() as tape1:\n","        # Scalar function: f(x, y) = x^2*y + y^3\n","        f = x[0]**2 * x[1] + x[1]**3\n","    grad = tape1.gradient(f, x)  # [2xy, x^2 + 3y^2]\n","hessian = tape2.jacobian(grad, x)\n","\n","print(f\"\\nf(x, y) = x^2*y + y^3, at (x, y) = ({x[0].numpy()}, {x[1].numpy()})\")\n","print(f\"f = {f.numpy()}\")\n","print(f\"\\nGradient: {grad.numpy()}\")\n","print(f\"  Expected: [2xy, x^2 + 3y^2] = [4, 13]\")\n","print(f\"\\nHessian:\")\n","print(f\"{hessian.numpy()}\")\n","print(f\"  Expected:\")\n","print(f\"  [2y,  2x ]   = [4, 2]\")\n","print(f\"  [2x,  6y ]   = [2, 12]\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srxJFP_KWcC9","executionInfo":{"status":"ok","timestamp":1771138690698,"user_tz":480,"elapsed":70,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"2eecab15-77b1-460f-bed5-370ee897190f"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","              CUSTOM GRADIENTS\n","============================================================\n","\n","Input: [3. 4.]\n","Gradient (clipped to norm 1.0): [0.70710677 0.70710677]\n","Gradient norm: 1.0000\n"]}],"source":["# ============================================================================\n","#                    CUSTOM GRADIENTS\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"              CUSTOM GRADIENTS\")\n","print(\"=\"*60)\n","\n","# Sometimes you need to define custom gradients:\n","# - For non-differentiable operations (like argmax)\n","# - For numerical stability\n","# - For custom backward passes (like straight-through estimators)\n","\n","@tf.custom_gradient\n","def clip_gradient_norm(x, clip_value=1.0):\n","    \"\"\"\n","    Forward: identity function\n","    Backward: clip gradient norm\n","    \"\"\"\n","    def grad(dy):\n","        # Clip the incoming gradient\n","        norm = tf.norm(dy)\n","        clipped = tf.cond(\n","            norm > clip_value,\n","            lambda: dy * clip_value / norm,\n","            lambda: dy\n","        )\n","        return clipped  # Only return gradient for 'x'\n","    return x, grad\n","\n","# Test custom gradient\n","x = tf.Variable([3.0, 4.0])  # Gradient will have norm 5 (3-4-5 triangle)\n","\n","with tf.GradientTape() as tape:\n","    y = clip_gradient_norm(x, clip_value=1.0)\n","    loss = tf.reduce_sum(y)  # Gradient would be [1, 1] but we pass [3, 4]\n","\n","# Manually set upstream gradient to [3, 4]\n","grad = tape.gradient(loss, x)\n","print(f\"\\nInput: {x.numpy()}\")\n","print(f\"Gradient (clipped to norm 1.0): {grad.numpy()}\")\n","print(f\"Gradient norm: {tf.norm(grad).numpy():.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hl8-8EpEWcC9","executionInfo":{"status":"ok","timestamp":1771138690737,"user_tz":480,"elapsed":33,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"4f414187-9ee9-4a7e-8317-4fc45736c8e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","         STRAIGHT-THROUGH ESTIMATOR\n","============================================================\n","\n","Input:   [0.3 0.7 1.2 2.5]\n","Rounded: [0. 1. 1. 2.]\n","Gradient (straight-through): [0. 2. 2. 4.]\n","\n"," Note: Round is non-differentiable, but we can still train!\n"]}],"source":["# ============================================================================\n","#                    STRAIGHT-THROUGH ESTIMATOR\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"         STRAIGHT-THROUGH ESTIMATOR\")\n","print(\"=\"*60)\n","\n","# The straight-through estimator is used for:\n","# - Binary/discrete operations that are non-differentiable\n","# - Quantization in neural networks\n","\n","@tf.custom_gradient\n","def straight_through_round(x):\n","    \"\"\"\n","    Forward: round to nearest integer\n","    Backward: pass gradient through unchanged (identity)\n","    \"\"\"\n","    def grad(dy):\n","        return dy  # Straight-through: gradient = identity\n","    return tf.round(x), grad\n","\n","@tf.custom_gradient\n","def straight_through_sign(x):\n","    \"\"\"\n","    Forward: sign function (-1, 0, or 1)\n","    Backward: gradient of hard tanh (1 if |x| <= 1, else 0)\n","    \"\"\"\n","    def grad(dy):\n","        # Gradient is 1 where |x| <= 1, 0 elsewhere\n","        return dy * tf.cast(tf.abs(x) <= 1, dy.dtype)\n","    return tf.sign(x), grad\n","\n","# Test\n","x = tf.Variable([0.3, 0.7, 1.2, 2.5])\n","\n","with tf.GradientTape() as tape:\n","    y = straight_through_round(x)\n","    loss = tf.reduce_sum(y ** 2)\n","\n","grad = tape.gradient(loss, x)\n","\n","print(f\"\\nInput:   {x.numpy()}\")\n","print(f\"Rounded: {y.numpy()}\")\n","print(f\"Gradient (straight-through): {grad.numpy()}\")\n","print(f\"\\n Note: Round is non-differentiable, but we can still train!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Uwxn2-LWcC9","executionInfo":{"status":"ok","timestamp":1771138690804,"user_tz":480,"elapsed":59,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"e4b5164d-e068-4f8b-aba0-554b818dfd50"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","            GRADIENT ACCUMULATION\n","============================================================\n","\n","Gradient Accumulation Pattern:\n","  1. Compute gradients for mini-batch\n","  2. Accumulate (sum or average) over N steps\n","  3. Apply accumulated gradients once\n","  4. Effective batch = mini_batch * N\n"]}],"source":["# ============================================================================\n","#                    GRADIENT ACCUMULATION\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"            GRADIENT ACCUMULATION\")\n","print(\"=\"*60)\n","\n","# Gradient accumulation is useful when:\n","# - Batch size is too large for GPU memory\n","# - You want effective larger batch sizes\n","\n","def train_with_accumulation(model, data, labels, batch_size, accumulation_steps, optimizer):\n","    \"\"\"\n","    Train with gradient accumulation.\n","    Effective batch size = batch_size * accumulation_steps\n","    \"\"\"\n","    n_samples = len(data)\n","    accumulated_gradients = [tf.zeros_like(v) for v in model.trainable_variables]\n","\n","    for step in range(accumulation_steps):\n","        # Get mini-batch\n","        start = (step * batch_size) % n_samples\n","        end = start + batch_size\n","        x_batch = data[start:end]\n","        y_batch = labels[start:end]\n","\n","        with tf.GradientTape() as tape:\n","            predictions = model(x_batch, training=True)\n","            loss = tf.reduce_mean(keras.losses.mse(y_batch, predictions))\n","\n","        # Compute gradients\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","\n","        # Accumulate (average over steps)\n","        accumulated_gradients = [\n","            acc + grad / accumulation_steps\n","            for acc, grad in zip(accumulated_gradients, gradients)\n","        ]\n","\n","    # Apply accumulated gradients\n","    optimizer.apply_gradients(zip(accumulated_gradients, model.trainable_variables))\n","    return loss\n","\n","print(\"\\nGradient Accumulation Pattern:\")\n","print(\"  1. Compute gradients for mini-batch\")\n","print(\"  2. Accumulate (sum or average) over N steps\")\n","print(\"  3. Apply accumulated gradients once\")\n","print(\"  4. Effective batch = mini_batch * N\")"]},{"cell_type":"markdown","metadata":{"id":"3WCMnLwcWcC9"},"source":["---\n","\n","# Part II: Building Operations from Scratch\n","\n","## Understanding Neural Network Primitives\n","\n","Before using Keras layers, let's understand what they do by building them ourselves."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PY-nVGvvWcC-","executionInfo":{"status":"ok","timestamp":1771138690998,"user_tz":480,"elapsed":185,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"c4b0dcc8-85a8-453d-9a62-6023923b39c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","           CONVOLUTION FROM SCRATCH\n","============================================================\n","\n","Input shape:  (1, 5, 5, 1)\n","Kernel shape: (3, 3, 1, 2)\n","Output shape: (1, 3, 3, 2)\n","Matches tf.nn.conv2d: True\n"]}],"source":["# ============================================================================\n","#                    CONVOLUTION FROM SCRATCH\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"           CONVOLUTION FROM SCRATCH\")\n","print(\"=\"*60)\n","\n","def conv2d_naive(input_tensor, kernel, stride=1, padding='VALID'):\n","    \"\"\"\n","    Naive 2D convolution implementation.\n","\n","    Parameters\n","    ----------\n","    input_tensor : tensor (batch, height, width, in_channels)\n","    kernel : tensor (kernel_h, kernel_w, in_channels, out_channels)\n","    stride : int\n","    padding : 'VALID' or 'SAME'\n","    \"\"\"\n","    batch_size = tf.shape(input_tensor)[0]\n","    in_h, in_w = input_tensor.shape[1], input_tensor.shape[2]\n","    k_h, k_w = kernel.shape[0], kernel.shape[1]\n","    out_channels = kernel.shape[3]\n","\n","    if padding == 'SAME':\n","        pad_h = k_h // 2\n","        pad_w = k_w // 2\n","        input_tensor = tf.pad(input_tensor,\n","                              [[0, 0], [pad_h, pad_h], [pad_w, pad_w], [0, 0]])\n","        in_h += 2 * pad_h\n","        in_w += 2 * pad_w\n","\n","    out_h = (in_h - k_h) // stride + 1\n","    out_w = (in_w - k_w) // stride + 1\n","\n","    output = tf.TensorArray(dtype=tf.float32, size=out_h * out_w)\n","    idx = 0\n","\n","    for i in range(out_h):\n","        for j in range(out_w):\n","            # Extract patch\n","            h_start = i * stride\n","            w_start = j * stride\n","            patch = input_tensor[:, h_start:h_start+k_h, w_start:w_start+k_w, :]\n","\n","            # Convolve: sum over (h, w, in_channels), keep out_channels\n","            # patch: (batch, k_h, k_w, in_c)\n","            # kernel: (k_h, k_w, in_c, out_c)\n","            conv = tf.einsum('bhwi,hwio->bo', patch, kernel)\n","            output = output.write(idx, conv)\n","            idx += 1\n","\n","    output = output.stack()  # (out_h*out_w, batch, out_c)\n","    output = tf.transpose(output, [1, 0, 2])  # (batch, out_h*out_w, out_c)\n","    output = tf.reshape(output, [batch_size, out_h, out_w, out_channels])\n","\n","    return output\n","\n","# Test our implementation\n","x = tf.random.normal((1, 5, 5, 1))  # 1 image, 5x5, 1 channel\n","kernel = tf.random.normal((3, 3, 1, 2))  # 3x3 kernel, 1->2 channels\n","\n","our_output = conv2d_naive(x, kernel, stride=1, padding='VALID')\n","tf_output = tf.nn.conv2d(x, kernel, strides=1, padding='VALID')\n","\n","print(f\"\\nInput shape:  {x.shape}\")\n","print(f\"Kernel shape: {kernel.shape}\")\n","print(f\"Output shape: {our_output.shape}\")\n","print(f\"Matches tf.nn.conv2d: {tf.reduce_all(tf.abs(our_output - tf_output) < 1e-5).numpy()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltjjl1lJWcC-","executionInfo":{"status":"ok","timestamp":1771138691020,"user_tz":480,"elapsed":26,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"934288c4-3bed-48d4-c468-c105ee7be02c"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","           MAX POOLING FROM SCRATCH\n","============================================================\n","\n","Input shape: (1, 4, 4, 2)\n","Input (channel 0):\n","[[ 1.  3.  5.  7.]\n"," [ 9. 11. 13. 15.]\n"," [17. 19. 21. 23.]\n"," [25. 27. 29. 31.]]\n","\n","Output shape: (1, 2, 2, 2)\n","Output (channel 0):\n","[[11. 15.]\n"," [27. 31.]]\n","\n","Matches tf.nn.max_pool2d: True\n"]}],"source":["# ============================================================================\n","#                    MAX POOLING FROM SCRATCH\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"           MAX POOLING FROM SCRATCH\")\n","print(\"=\"*60)\n","\n","def max_pool2d_naive(input_tensor, pool_size=2, stride=2):\n","    \"\"\"\n","    Naive max pooling implementation.\n","\n","    For each pool_size x pool_size window, take the maximum.\n","    \"\"\"\n","    batch_size = tf.shape(input_tensor)[0]\n","    in_h, in_w, channels = input_tensor.shape[1:]\n","\n","    out_h = (in_h - pool_size) // stride + 1\n","    out_w = (in_w - pool_size) // stride + 1\n","\n","    outputs = []\n","\n","    for i in range(out_h):\n","        row = []\n","        for j in range(out_w):\n","            h_start = i * stride\n","            w_start = j * stride\n","            # Extract window\n","            window = input_tensor[:, h_start:h_start+pool_size,\n","                                  w_start:w_start+pool_size, :]\n","            # Max over spatial dimensions\n","            pooled = tf.reduce_max(window, axis=[1, 2])\n","            row.append(pooled)\n","        outputs.append(tf.stack(row, axis=1))\n","\n","    return tf.stack(outputs, axis=1)\n","\n","# Test\n","x = tf.constant([[[[1., 2.], [3., 4.], [5., 6.], [7., 8.]],\n","                  [[9., 10.], [11., 12.], [13., 14.], [15., 16.]],\n","                  [[17., 18.], [19., 20.], [21., 22.], [23., 24.]],\n","                  [[25., 26.], [27., 28.], [29., 30.], [31., 32.]]]])\n","\n","print(f\"\\nInput shape: {x.shape}\")\n","print(f\"Input (channel 0):\")\n","print(x[0, :, :, 0].numpy())\n","\n","our_pool = max_pool2d_naive(x, pool_size=2, stride=2)\n","tf_pool = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='VALID')\n","\n","print(f\"\\nOutput shape: {our_pool.shape}\")\n","print(f\"Output (channel 0):\")\n","print(our_pool[0, :, :, 0].numpy())\n","print(f\"\\nMatches tf.nn.max_pool2d: {tf.reduce_all(our_pool == tf_pool).numpy()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeZuo5ITWcC-","executionInfo":{"status":"ok","timestamp":1771138691198,"user_tz":480,"elapsed":153,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"a07a1b69-5998-4377-8479-4e5196875f7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","        BATCH NORMALIZATION FROM SCRATCH\n","============================================================\n","\n","Input shape: (8, 4)\n","Input mean per feature: [ 0.32574826 -0.22160122  0.37827352  0.3575499 ]\n","Input std per feature:  [0.8102391  0.74234474 1.061351   1.0821929 ]\n","\n","Output (training) mean: [-2.9802322e-08  4.6566129e-08  7.4505806e-09 -2.2351742e-08]\n","Output (training) std:  [0.9999923 0.9999908 0.9999955 0.9999958]\n","\n"," After BatchNorm, each feature has ~0 mean and ~1 std!\n"]}],"source":["# ============================================================================\n","#                    BATCH NORMALIZATION FROM SCRATCH\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"        BATCH NORMALIZATION FROM SCRATCH\")\n","print(\"=\"*60)\n","\n","class BatchNormFromScratch:\n","    \"\"\"\n","    Batch Normalization implemented from scratch.\n","\n","    During training:\n","        x_norm = (x - batch_mean) / sqrt(batch_var + epsilon)\n","        y = gamma * x_norm + beta\n","\n","    During inference:\n","        Use running mean and variance instead of batch statistics.\n","    \"\"\"\n","\n","    def __init__(self, num_features, epsilon=1e-5, momentum=0.1):\n","        self.epsilon = epsilon\n","        self.momentum = momentum\n","\n","        # Learnable parameters\n","        self.gamma = tf.Variable(tf.ones(num_features), name='gamma')\n","        self.beta = tf.Variable(tf.zeros(num_features), name='beta')\n","\n","        # Running statistics (not trainable)\n","        self.running_mean = tf.Variable(tf.zeros(num_features), trainable=False)\n","        self.running_var = tf.Variable(tf.ones(num_features), trainable=False)\n","\n","    def __call__(self, x, training=True):\n","        if training:\n","            # Compute batch statistics\n","            batch_mean = tf.reduce_mean(x, axis=0)\n","            batch_var = tf.math.reduce_variance(x, axis=0)\n","\n","            # Update running statistics\n","            self.running_mean.assign(\n","                (1 - self.momentum) * self.running_mean + self.momentum * batch_mean\n","            )\n","            self.running_var.assign(\n","                (1 - self.momentum) * self.running_var + self.momentum * batch_var\n","            )\n","\n","            mean, var = batch_mean, batch_var\n","        else:\n","            mean, var = self.running_mean, self.running_var\n","\n","        # Normalize\n","        x_norm = (x - mean) / tf.sqrt(var + self.epsilon)\n","\n","        # Scale and shift\n","        return self.gamma * x_norm + self.beta\n","\n","    @property\n","    def trainable_variables(self):\n","        return [self.gamma, self.beta]\n","\n","# Test\n","bn = BatchNormFromScratch(num_features=4)\n","x = tf.random.normal((8, 4))  # Batch of 8, 4 features\n","\n","y_train = bn(x, training=True)\n","y_eval = bn(x, training=False)\n","\n","print(f\"\\nInput shape: {x.shape}\")\n","print(f\"Input mean per feature: {tf.reduce_mean(x, axis=0).numpy()}\")\n","print(f\"Input std per feature:  {tf.math.reduce_std(x, axis=0).numpy()}\")\n","print(f\"\\nOutput (training) mean: {tf.reduce_mean(y_train, axis=0).numpy()}\")\n","print(f\"Output (training) std:  {tf.math.reduce_std(y_train, axis=0).numpy()}\")\n","print(f\"\\n After BatchNorm, each feature has ~0 mean and ~1 std!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YR_REX3RWcC-","executionInfo":{"status":"ok","timestamp":1771138691245,"user_tz":480,"elapsed":59,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"f1a85000-fe79-4a7a-9bfb-ca3dc93bd0ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","        LAYER NORMALIZATION FROM SCRATCH\n","============================================================\n","\n","Input shape: (2, 3, 4)\n","\n","For sample [0, 0, :]:\n","  Input:  [ 0.65648675 -0.4130517   0.33997506 -1.0056272 ]\n","  Output: [ 1.1744822  -0.47392502  0.6866642  -1.3872216 ]\n","  Output mean: -0.000000\n","  Output std:  1.0000\n","\n"," Key difference:\n","  BatchNorm: normalize across batch (for each feature)\n","  LayerNorm: normalize across features (for each sample)\n"]}],"source":["# ============================================================================\n","#                    LAYER NORMALIZATION FROM SCRATCH\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"        LAYER NORMALIZATION FROM SCRATCH\")\n","print(\"=\"*60)\n","\n","class LayerNormFromScratch:\n","    \"\"\"\n","    Layer Normalization: Normalize across features (not batch).\n","\n","    Used in Transformers because:\n","    - Works with any batch size (including 1)\n","    - No running statistics needed\n","    - Each sample normalized independently\n","    \"\"\"\n","\n","    def __init__(self, normalized_shape, epsilon=1e-5):\n","        self.epsilon = epsilon\n","        self.normalized_shape = normalized_shape\n","\n","        # Learnable parameters\n","        self.gamma = tf.Variable(tf.ones(normalized_shape), name='gamma')\n","        self.beta = tf.Variable(tf.zeros(normalized_shape), name='beta')\n","\n","    def __call__(self, x):\n","        # Compute statistics across last dimensions\n","        mean = tf.reduce_mean(x, axis=-1, keepdims=True)\n","        var = tf.math.reduce_variance(x, axis=-1, keepdims=True)\n","\n","        # Normalize\n","        x_norm = (x - mean) / tf.sqrt(var + self.epsilon)\n","\n","        # Scale and shift\n","        return self.gamma * x_norm + self.beta\n","\n","    @property\n","    def trainable_variables(self):\n","        return [self.gamma, self.beta]\n","\n","# Test\n","ln = LayerNormFromScratch(normalized_shape=4)\n","x = tf.random.normal((2, 3, 4))  # (batch, seq, features)\n","\n","y = ln(x)\n","\n","print(f\"\\nInput shape: {x.shape}\")\n","print(f\"\\nFor sample [0, 0, :]:\")\n","print(f\"  Input:  {x[0, 0, :].numpy()}\")\n","print(f\"  Output: {y[0, 0, :].numpy()}\")\n","print(f\"  Output mean: {tf.reduce_mean(y[0, 0, :]).numpy():.6f}\")\n","print(f\"  Output std:  {tf.math.reduce_std(y[0, 0, :]).numpy():.4f}\")\n","\n","print(f\"\\n Key difference:\")\n","print(f\"  BatchNorm: normalize across batch (for each feature)\")\n","print(f\"  LayerNorm: normalize across features (for each sample)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D4Ok8o68WcC_","executionInfo":{"status":"ok","timestamp":1771138694697,"user_tz":480,"elapsed":3452,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"166c8b5a-a437-4b8d-9a74-7c8291763669"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","            DROPOUT FROM SCRATCH\n","============================================================\n","Input: all ones, shape (2, 10)\n","\n","Dropout sample 1: [0. 2. 2. 0. 0. 2. 0. 2. 2. 0.]\n","Dropout sample 2: [0. 2. 2. 2. 0. 0. 2. 2. 2. 0.]\n","Dropout sample 3: [2. 0. 2. 2. 2. 0. 0. 2. 2. 2.]\n","\n","During inference (training=False):\n","  Output: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n","\n","Average over 1000 samples: 1.0045 (should be ~1.0)\n"]}],"source":["# ============================================================================\n","#                    DROPOUT FROM SCRATCH\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"            DROPOUT FROM SCRATCH\")\n","print(\"=\"*60)\n","\n","def dropout_from_scratch(x, rate=0.5, training=True):\n","    \"\"\"\n","    Dropout: Randomly zero out neurons during training.\n","\n","    Key insight: Scale by 1/(1-rate) during training so that\n","    expected value remains the same during inference.\n","    \"\"\"\n","    if not training or rate == 0:\n","        return x\n","\n","    # Create random mask\n","    keep_prob = 1 - rate\n","    mask = tf.cast(\n","        tf.random.uniform(tf.shape(x)) < keep_prob,\n","        dtype=x.dtype\n","    )\n","\n","    # Apply mask and scale\n","    return (x * mask) / keep_prob\n","\n","# Test\n","x = tf.ones((2, 10))\n","\n","print(f\"Input: all ones, shape {x.shape}\")\n","print(f\"\")\n","\n","# Multiple dropout samples\n","for i in range(3):\n","    dropped = dropout_from_scratch(x, rate=0.5, training=True)\n","    print(f\"Dropout sample {i+1}: {dropped[0].numpy()}\")\n","\n","print(f\"\\nDuring inference (training=False):\")\n","print(f\"  Output: {dropout_from_scratch(x, rate=0.5, training=False)[0].numpy()}\")\n","\n","# Verify expected value is preserved\n","samples = tf.stack([dropout_from_scratch(x, rate=0.5) for _ in range(1000)])\n","print(f\"\\nAverage over 1000 samples: {tf.reduce_mean(samples).numpy():.4f} (should be ~1.0)\")"]},{"cell_type":"markdown","source":["---\n","\n","# Part III: Custom Layers Using Primitives\n","\n","## Building Layers with tf.Variable Only\n","\n","Before using Keras's layer system, let's build fully functional layers using only basic TensorFlow operations. This shows exactly what happens under the hood."],"metadata":{"id":"4XqEZxTtWcC_"}},{"cell_type":"code","source":["# ============================================================================\n","#                    DENSE LAYER FROM PRIMITIVES\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"          DENSE LAYER FROM PRIMITIVES\")\n","print(\"=\"*60)\n","\n","class DenseLayerPrimitive:\n","    \"\"\"\n","    Fully connected layer using only tf.Variable.\n","\n","    Mathematically: y = activation(x @ W + b)\n","    \"\"\"\n","\n","    def __init__(self, in_features, out_features, activation=None, use_bias=True):\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.use_bias = use_bias\n","\n","        # Select activation\n","        self.activation = {\n","            None: lambda x: x,\n","            'relu': tf.nn.relu,\n","            'sigmoid': tf.nn.sigmoid,\n","            'tanh': tf.nn.tanh,\n","            'softmax': lambda x: tf.nn.softmax(x, axis=-1)\n","        }.get(activation, activation)  # Allow passing functions directly\n","\n","        # He initialization for weights\n","        stddev = np.sqrt(2.0 / in_features)\n","        self.W = tf.Variable(\n","            tf.random.normal((in_features, out_features), stddev=stddev),\n","            trainable=True,\n","            name='kernel'\n","        )\n","\n","        if use_bias:\n","            self.b = tf.Variable(\n","                tf.zeros(out_features),\n","                trainable=True,\n","                name='bias'\n","            )\n","\n","    def __call__(self, x):\n","        \"\"\"Forward pass: y = activation(x @ W + b)\"\"\"\n","        out = x @ self.W\n","        if self.use_bias:\n","            out = out + self.b\n","        return self.activation(out)\n","\n","    @property\n","    def trainable_variables(self):\n","        if self.use_bias:\n","            return [self.W, self.b]\n","        return [self.W]\n","\n","    def __repr__(self):\n","        return f\"DenseLayerPrimitive({self.in_features}, {self.out_features})\"\n","\n","# Test\n","dense = DenseLayerPrimitive(4, 3, activation='relu')\n","x = tf.random.normal((2, 4))\n","y = dense(x)\n","\n","print(f\"\\nDenseLayerPrimitive(4, 3, activation='relu')\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"Weight shape: {dense.W.shape}\")\n","print(f\"Bias shape:   {dense.b.shape}\")\n","print(f\"\\nOutput:\\n{y.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gesc0NBxWcC_","executionInfo":{"status":"ok","timestamp":1771138694780,"user_tz":480,"elapsed":71,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"f0ffdf4c-0e48-4ef6-b714-8eb337d68960"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","          DENSE LAYER FROM PRIMITIVES\n","============================================================\n","\n","DenseLayerPrimitive(4, 3, activation='relu')\n","Input shape:  (2, 4)\n","Output shape: (2, 3)\n","Weight shape: (4, 3)\n","Bias shape:   (3,)\n","\n","Output:\n","[[0.         0.         0.46504724]\n"," [0.         0.         0.8249154 ]]\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    CONV2D LAYER FROM PRIMITIVES\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"          CONV2D LAYER FROM PRIMITIVES\")\n","print(\"=\"*60)\n","\n","class Conv2DLayerPrimitive:\n","    \"\"\"\n","    2D Convolutional layer using only tf.Variable and tf.nn.conv2d.\n","    \"\"\"\n","\n","    def __init__(self, in_channels, out_channels, kernel_size,\n","                 stride=1, padding='SAME', activation=None, use_bias=True):\n","        self.stride = stride\n","        self.padding = padding\n","        self.use_bias = use_bias\n","\n","        # Handle kernel_size as int or tuple\n","        if isinstance(kernel_size, int):\n","            kernel_size = (kernel_size, kernel_size)\n","\n","        # Select activation\n","        self.activation = {\n","            None: lambda x: x,\n","            'relu': tf.nn.relu,\n","            'sigmoid': tf.nn.sigmoid,\n","            'tanh': tf.nn.tanh,\n","        }.get(activation, activation)\n","\n","        # He initialization\n","        fan_in = kernel_size[0] * kernel_size[1] * in_channels\n","        stddev = np.sqrt(2.0 / fan_in)\n","\n","        # Kernel shape: (height, width, in_channels, out_channels)\n","        self.kernel = tf.Variable(\n","            tf.random.normal((kernel_size[0], kernel_size[1], in_channels, out_channels),\n","                           stddev=stddev),\n","            trainable=True,\n","            name='kernel'\n","        )\n","\n","        if use_bias:\n","            self.bias = tf.Variable(\n","                tf.zeros(out_channels),\n","                trainable=True,\n","                name='bias'\n","            )\n","\n","    def __call__(self, x):\n","        \"\"\"Forward pass using tf.nn.conv2d\"\"\"\n","        out = tf.nn.conv2d(x, self.kernel, strides=self.stride, padding=self.padding)\n","        if self.use_bias:\n","            out = out + self.bias\n","        return self.activation(out)\n","\n","    @property\n","    def trainable_variables(self):\n","        if self.use_bias:\n","            return [self.kernel, self.bias]\n","        return [self.kernel]\n","\n","# Test\n","conv = Conv2DLayerPrimitive(3, 16, kernel_size=3, activation='relu')\n","x = tf.random.normal((1, 28, 28, 3))  # 1 image, 28x28, 3 channels\n","y = conv(x)\n","\n","print(f\"\\nConv2DLayerPrimitive(3, 16, kernel_size=3)\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"Kernel shape: {conv.kernel.shape}\")\n","print(f\"Parameters:   {np.prod(conv.kernel.shape) + conv.bias.shape[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSWj-SXwWcC_","executionInfo":{"status":"ok","timestamp":1771138694801,"user_tz":480,"elapsed":17,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"2d7f77c5-694d-4ac8-a8ab-8e2040eb60ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","          CONV2D LAYER FROM PRIMITIVES\n","============================================================\n","\n","Conv2DLayerPrimitive(3, 16, kernel_size=3)\n","Input shape:  (1, 28, 28, 3)\n","Output shape: (1, 28, 28, 16)\n","Kernel shape: (3, 3, 3, 16)\n","Parameters:   448\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    COMPLETE CNN FROM PRIMITIVES\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"          COMPLETE CNN FROM PRIMITIVES\")\n","print(\"=\"*60)\n","\n","class CNNFromPrimitives:\n","    \"\"\"\n","    A complete CNN built using only primitive layers.\n","\n","    Architecture:\n","        Conv(3x3) -> ReLU -> MaxPool -> Conv(3x3) -> ReLU -> MaxPool -> Flatten -> Dense -> Dense\n","    \"\"\"\n","\n","    def __init__(self, input_shape, num_classes):\n","        self.input_shape = input_shape\n","        in_channels = input_shape[-1]\n","\n","        # Convolutional layers\n","        self.conv1 = Conv2DLayerPrimitive(in_channels, 32, kernel_size=3, activation='relu')\n","        self.conv2 = Conv2DLayerPrimitive(32, 64, kernel_size=3, activation='relu')\n","\n","        # Calculate flattened size after convolutions and pooling\n","        # With SAME padding and 2x2 pooling twice: H/4, W/4\n","        h, w = input_shape[0] // 4, input_shape[1] // 4\n","        flat_size = h * w * 64\n","\n","        # Dense layers\n","        self.fc1 = DenseLayerPrimitive(flat_size, 128, activation='relu')\n","        self.fc2 = DenseLayerPrimitive(128, num_classes, activation='softmax')\n","\n","        self.layers = [self.conv1, self.conv2, self.fc1, self.fc2]\n","\n","    def __call__(self, x, training=True):\n","        # Conv block 1\n","        x = self.conv1(x)\n","        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n","\n","        # Conv block 2\n","        x = self.conv2(x)\n","        x = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='SAME')\n","\n","        # Flatten\n","        x = tf.reshape(x, (tf.shape(x)[0], -1))\n","\n","        # Dense layers\n","        x = self.fc1(x)\n","        if training:\n","            x = dropout_from_scratch(x, rate=0.5, training=True)\n","        x = self.fc2(x)\n","\n","        return x\n","\n","    @property\n","    def trainable_variables(self):\n","        variables = []\n","        for layer in self.layers:\n","            variables.extend(layer.trainable_variables)\n","        return variables\n","\n","    def summary(self):\n","        print(\"\\n\" + \"=\"*50)\n","        print(\"        CNN FROM PRIMITIVES - SUMMARY\")\n","        print(\"=\"*50)\n","        total = 0\n","        for i, layer in enumerate(self.layers):\n","            params = sum(np.prod(v.shape) for v in layer.trainable_variables)\n","            total += params\n","            print(f\"Layer {i+1}: {layer.__class__.__name__:20} | Params: {params:,}\")\n","        print(\"-\"*50)\n","        print(f\"Total trainable parameters: {total:,}\")\n","\n","# Create and test\n","cnn = CNNFromPrimitives(input_shape=(28, 28, 1), num_classes=10)\n","cnn.summary()\n","\n","# Test forward pass\n","x = tf.random.normal((4, 28, 28, 1))\n","y = cnn(x)\n","print(f\"\\nInput shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"Output sum per sample: {tf.reduce_sum(y, axis=1).numpy()}  (should be ~1.0)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BvCl_LZwWcC_","executionInfo":{"status":"ok","timestamp":1771138695141,"user_tz":480,"elapsed":336,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"2351c669-1474-44bd-b980-513540358999"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","          COMPLETE CNN FROM PRIMITIVES\n","============================================================\n","\n","==================================================\n","        CNN FROM PRIMITIVES - SUMMARY\n","==================================================\n","Layer 1: Conv2DLayerPrimitive | Params: 320\n","Layer 2: Conv2DLayerPrimitive | Params: 18,496\n","Layer 3: DenseLayerPrimitive  | Params: 401,536\n","Layer 4: DenseLayerPrimitive  | Params: 1,290\n","--------------------------------------------------\n","Total trainable parameters: 421,642\n","\n","Input shape:  (4, 28, 28, 1)\n","Output shape: (4, 10)\n","Output sum per sample: [0.9999999 1.        1.        0.9999999]  (should be ~1.0)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# Part IV: Custom Keras Layers\n","\n","## The Proper Way to Build Custom Layers\n","\n","Keras provides a clean API for custom layers with:\n","- **`build()`**: Create weights when input shape is known\n","- **`call()`**: Define the forward pass\n","- **`get_config()`**: Enable serialization\n","\n","This gives you all the benefits of primitives PLUS:\n","- Automatic weight tracking\n","- Serialization/deserialization\n","- Integration with `model.fit()`\n","- Proper shape inference"],"metadata":{"id":"CPUeDPKIWcC_"}},{"cell_type":"code","source":["# ============================================================================\n","#                    CUSTOM KERAS LAYER: BASICS\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"          CUSTOM KERAS LAYER: BASICS\")\n","print(\"=\"*60)\n","\n","class CustomDenseLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom Dense layer demonstrating the Keras layer API.\n","\n","    Key methods:\n","    - __init__: Store configuration (no weights yet!)\n","    - build: Create weights when input shape is known\n","    - call: Forward pass\n","    - get_config: For serialization\n","    \"\"\"\n","\n","    def __init__(self, units, activation=None, use_bias=True, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","        self.activation = keras.activations.get(activation)\n","        self.use_bias = use_bias\n","\n","    def build(self, input_shape):\n","        \"\"\"\n","        Create weights. Called automatically the first time the layer is used.\n","\n","        self.add_weight() creates a tf.Variable and registers it properly.\n","        \"\"\"\n","        self.kernel = self.add_weight(\n","            name='kernel',\n","            shape=(input_shape[-1], self.units),\n","            initializer='glorot_uniform',  # Xavier initialization\n","            trainable=True\n","        )\n","\n","        if self.use_bias:\n","            self.bias = self.add_weight(\n","                name='bias',\n","                shape=(self.units,),\n","                initializer='zeros',\n","                trainable=True\n","            )\n","\n","        # Mark as built\n","        super().build(input_shape)\n","\n","    def call(self, inputs):\n","        \"\"\"Forward pass.\"\"\"\n","        output = tf.matmul(inputs, self.kernel)\n","        if self.use_bias:\n","            output = output + self.bias\n","        if self.activation is not None:\n","            output = self.activation(output)\n","        return output\n","\n","    def get_config(self):\n","        \"\"\"Enable serialization.\"\"\"\n","        config = super().get_config()\n","        config.update({\n","            'units': self.units,\n","            'activation': keras.activations.serialize(self.activation),\n","            'use_bias': self.use_bias\n","        })\n","        return config\n","\n","# Test custom layer\n","custom_dense = CustomDenseLayer(32, activation='relu')\n","x = tf.random.normal((4, 16))\n","y = custom_dense(x)  # This triggers build()\n","\n","print(f\"\\nCustomDenseLayer(32, activation='relu')\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"Kernel shape: {custom_dense.kernel.shape}\")\n","print(f\"Trainable variables: {len(custom_dense.trainable_variables)}\")\n","print(f\"\\nConfig: {custom_dense.get_config()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnKJDd05WcC_","executionInfo":{"status":"ok","timestamp":1771138695208,"user_tz":480,"elapsed":64,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"3a54ba8c-4d81-4eb3-bbbd-e8034d6f7e0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","          CUSTOM KERAS LAYER: BASICS\n","============================================================\n","\n","CustomDenseLayer(32, activation='relu')\n","Input shape:  (4, 16)\n","Output shape: (4, 32)\n","Kernel shape: (16, 32)\n","Trainable variables: 2\n","\n","Config: {'name': 'custom_dense_layer', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 32, 'activation': 'relu', 'use_bias': True}\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    CUSTOM LAYER: SELF-ATTENTION\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"         CUSTOM LAYER: SELF-ATTENTION\")\n","print(\"=\"*60)\n","\n","class SelfAttentionLayer(keras.layers.Layer):\n","    \"\"\"\n","    Self-Attention layer (simplified version of Transformer attention).\n","\n","    Attention(Q, K, V) = softmax(Q @ K^T / sqrt(d_k)) @ V\n","\n","    In self-attention, Q, K, V all come from the same input.\n","    \"\"\"\n","\n","    def __init__(self, embed_dim, num_heads=1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.head_dim = embed_dim // num_heads\n","\n","        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n","\n","    def build(self, input_shape):\n","        # Linear projections for Q, K, V\n","        self.W_q = self.add_weight(\n","            name='W_q',\n","            shape=(input_shape[-1], self.embed_dim),\n","            initializer='glorot_uniform'\n","        )\n","        self.W_k = self.add_weight(\n","            name='W_k',\n","            shape=(input_shape[-1], self.embed_dim),\n","            initializer='glorot_uniform'\n","        )\n","        self.W_v = self.add_weight(\n","            name='W_v',\n","            shape=(input_shape[-1], self.embed_dim),\n","            initializer='glorot_uniform'\n","        )\n","        self.W_o = self.add_weight(\n","            name='W_o',\n","            shape=(self.embed_dim, self.embed_dim),\n","            initializer='glorot_uniform'\n","        )\n","        super().build(input_shape)\n","\n","    def call(self, inputs, mask=None):\n","        batch_size = tf.shape(inputs)[0]\n","        seq_len = tf.shape(inputs)[1]\n","\n","        # Linear projections\n","        Q = inputs @ self.W_q  # (batch, seq, embed)\n","        K = inputs @ self.W_k\n","        V = inputs @ self.W_v\n","\n","        # Reshape for multi-head attention\n","        Q = tf.reshape(Q, (batch_size, seq_len, self.num_heads, self.head_dim))\n","        K = tf.reshape(K, (batch_size, seq_len, self.num_heads, self.head_dim))\n","        V = tf.reshape(V, (batch_size, seq_len, self.num_heads, self.head_dim))\n","\n","        # Transpose to (batch, heads, seq, head_dim)\n","        Q = tf.transpose(Q, [0, 2, 1, 3])\n","        K = tf.transpose(K, [0, 2, 1, 3])\n","        V = tf.transpose(V, [0, 2, 1, 3])\n","\n","        # Attention scores: Q @ K^T / sqrt(d_k)\n","        scale = tf.sqrt(tf.cast(self.head_dim, tf.float32))\n","        scores = tf.matmul(Q, K, transpose_b=True) / scale  # (batch, heads, seq, seq)\n","\n","        # Apply mask if provided\n","        if mask is not None:\n","            scores += (1 - mask) * -1e9\n","\n","        # Softmax\n","        attention_weights = tf.nn.softmax(scores, axis=-1)\n","\n","        # Apply attention to values\n","        context = tf.matmul(attention_weights, V)  # (batch, heads, seq, head_dim)\n","\n","        # Reshape back\n","        context = tf.transpose(context, [0, 2, 1, 3])  # (batch, seq, heads, head_dim)\n","        context = tf.reshape(context, (batch_size, seq_len, self.embed_dim))\n","\n","        # Output projection\n","        output = context @ self.W_o\n","\n","        return output, attention_weights\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            'embed_dim': self.embed_dim,\n","            'num_heads': self.num_heads\n","        })\n","        return config\n","\n","# Test\n","attention = SelfAttentionLayer(embed_dim=64, num_heads=4)\n","x = tf.random.normal((2, 10, 64))  # (batch, seq_len, embed_dim)\n","output, weights = attention(x)\n","\n","print(f\"\\nSelfAttentionLayer(embed_dim=64, num_heads=4)\")\n","print(f\"Input shape:            {x.shape}\")\n","print(f\"Output shape:           {output.shape}\")\n","print(f\"Attention weights shape: {weights.shape}\")\n","print(f\"Trainable parameters:   {sum(np.prod(v.shape) for v in attention.trainable_variables):,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lfKOP_WWWcDA","executionInfo":{"status":"ok","timestamp":1771138695334,"user_tz":480,"elapsed":83,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"ad41adf1-3e08-4661-f8e6-75dbc8bf8f7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","         CUSTOM LAYER: SELF-ATTENTION\n","============================================================\n","\n","SelfAttentionLayer(embed_dim=64, num_heads=4)\n","Input shape:            (2, 10, 64)\n","Output shape:           (2, 10, 64)\n","Attention weights shape: (2, 4, 10, 10)\n","Trainable parameters:   16,384\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    CUSTOM LAYER: SPECTRAL NORMALIZATION\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"       CUSTOM LAYER: SPECTRAL NORMALIZATION\")\n","print(\"=\"*60)\n","\n","class SpectralNormalization(keras.layers.Wrapper):\n","    \"\"\"\n","    Spectral Normalization wrapper for layers.\n","\n","    Constrains the spectral norm (largest singular value) of the weight matrix.\n","    Used in GANs to stabilize training.\n","\n","    W_normalized = W / sigma(W)\n","    where sigma(W) is the largest singular value.\n","    \"\"\"\n","\n","    def __init__(self, layer, power_iterations=1, epsilon=1e-12, **kwargs):\n","        super().__init__(layer, **kwargs)\n","        self.power_iterations = power_iterations\n","        self.epsilon = epsilon\n","\n","    def build(self, input_shape):\n","        self.layer.build(input_shape)\n","\n","        # Get the weight matrix\n","        self.w = self.layer.kernel\n","        w_shape = self.w.shape.as_list()\n","\n","        # Flatten weight to 2D for SVD\n","        self.w_flat_shape = (np.prod(w_shape[:-1]), w_shape[-1])\n","\n","        # Initialize u vector (for power iteration)\n","        self.u = self.add_weight(\n","            name='u',\n","            shape=(1, w_shape[-1]),\n","            initializer='random_normal',\n","            trainable=False\n","        )\n","\n","        super().build(input_shape)\n","\n","    def call(self, inputs, training=True):\n","        # Power iteration to estimate largest singular value\n","        w_flat = tf.reshape(self.w, self.w_flat_shape)\n","\n","        u = self.u\n","        for _ in range(self.power_iterations):\n","            # v = W^T u / ||W^T u||\n","            v = tf.matmul(u, tf.transpose(w_flat))\n","            v = v / (tf.norm(v, ord='euclidean') + self.epsilon)\n","\n","            # u = W v / ||W v||\n","            u = tf.matmul(v, w_flat)\n","            u = u / (tf.norm(u, ord='euclidean') + self.epsilon)\n","\n","        if training:\n","            self.u.assign(u)\n","\n","        # Spectral norm: sigma = u^T W v\n","        # Corrected calculation for row vectors u (1, out_features) and v (1, in_features)\n","        # The formula should be v W u^T\n","        sigma = tf.matmul(tf.matmul(v, w_flat), tf.transpose(u))\n","\n","        # Normalize weight\n","        w_normalized = self.w / sigma[0, 0]\n","\n","        # Manually perform the forward pass of the wrapped layer using w_normalized.\n","        # This assumes the wrapped layer is a Dense layer based on the test case.\n","        output = tf.matmul(inputs, w_normalized)\n","\n","        # If the wrapped layer has a bias and uses it, add it.\n","        if hasattr(self.layer, 'bias') and self.layer.use_bias:\n","            output = output + self.layer.bias\n","\n","        # If the wrapped layer has an activation function, apply it.\n","        if hasattr(self.layer, 'activation') and self.layer.activation is not None:\n","            output = self.layer.activation(output)\n","\n","        return output\n","\n","# Test\n","base_layer = layers.Dense(64)\n","spectral_dense = SpectralNormalization(base_layer)\n","x = tf.random.normal((4, 32))\n","y = spectral_dense(x)\n","\n","print(f\"\\nSpectralNormalization(Dense(64))\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"\\n Use case: Stabilize GAN discriminator training\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFYq5xJbWcDA","executionInfo":{"status":"ok","timestamp":1771138695537,"user_tz":480,"elapsed":182,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"4ad701b5-a44b-4c7c-c4fe-fa65bf8fcae0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","       CUSTOM LAYER: SPECTRAL NORMALIZATION\n","============================================================\n","\n","SpectralNormalization(Dense(64))\n","Input shape:  (4, 32)\n","Output shape: (4, 64)\n","\n"," Use case: Stabilize GAN discriminator training\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# Part V: Advanced Architectures\n","\n","## Building Modern Deep Learning Components\n","\n","Now let's build advanced architectural components used in state-of-the-art models:\n","\n","- **Residual Blocks** (ResNet)\n","- **Squeeze-and-Excitation** (SENet)\n","- **Transformer Encoder Block**\n","- **Custom Normalization Layers**"],"metadata":{"id":"biOHWrOFWcDA"}},{"cell_type":"code","source":["# ============================================================================\n","#                    RESIDUAL BLOCK (ResNet Style)\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"           RESIDUAL BLOCK (ResNet)\")\n","print(\"=\"*60)\n","\n","class ResidualBlock(keras.layers.Layer):\n","    \"\"\"\n","    Residual Block: y = F(x) + x\n","\n","    The key insight: learning residual F(x) = y - x is easier than learning y directly.\n","    This enables training very deep networks (100+ layers).\n","    \"\"\"\n","\n","    def __init__(self, filters, kernel_size=3, stride=1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.filters = filters\n","        self.stride = stride\n","\n","        # Main path\n","        self.conv1 = layers.Conv2D(filters, kernel_size, strides=stride,\n","                                    padding='same', use_bias=False)\n","        self.bn1 = layers.BatchNormalization()\n","\n","        self.conv2 = layers.Conv2D(filters, kernel_size, strides=1,\n","                                    padding='same', use_bias=False)\n","        self.bn2 = layers.BatchNormalization()\n","\n","        # Skip connection (identity or projection)\n","        self.skip_conv = None\n","        self.skip_bn = None\n","\n","    def build(self, input_shape):\n","        # Need projection if dimensions change\n","        if input_shape[-1] != self.filters or self.stride != 1:\n","            self.skip_conv = layers.Conv2D(self.filters, 1, strides=self.stride,\n","                                           padding='same', use_bias=False)\n","            self.skip_bn = layers.BatchNormalization()\n","        super().build(input_shape)\n","\n","    def call(self, inputs, training=False):\n","        # Main path\n","        x = self.conv1(inputs)\n","        x = self.bn1(x, training=training)\n","        x = tf.nn.relu(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x, training=training)\n","\n","        # Skip connection\n","        if self.skip_conv is not None:\n","            skip = self.skip_conv(inputs)\n","            skip = self.skip_bn(skip, training=training)\n","        else:\n","            skip = inputs\n","\n","        # Add and activate\n","        return tf.nn.relu(x + skip)\n","\n","# Test\n","res_block = ResidualBlock(64, stride=1)\n","x = tf.random.normal((2, 32, 32, 64))\n","y = res_block(x)\n","\n","print(f\"\\nResidualBlock(64)\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","\n","# With downsampling\n","res_block_down = ResidualBlock(128, stride=2)\n","y_down = res_block_down(x)\n","print(f\"\\nResidualBlock(128, stride=2)\")\n","print(f\"Output shape: {y_down.shape}  (spatial dims halved, channels doubled)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqnNTvJTWcDA","executionInfo":{"status":"ok","timestamp":1771138695862,"user_tz":480,"elapsed":331,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"26a8ec6a-b032-4dcb-d4e5-d4b844e082cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","           RESIDUAL BLOCK (ResNet)\n","============================================================\n","\n","ResidualBlock(64)\n","Input shape:  (2, 32, 32, 64)\n","Output shape: (2, 32, 32, 64)\n","\n","ResidualBlock(128, stride=2)\n","Output shape: (2, 16, 16, 128)  (spatial dims halved, channels doubled)\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    SQUEEZE-AND-EXCITATION BLOCK\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"         SQUEEZE-AND-EXCITATION BLOCK\")\n","print(\"=\"*60)\n","\n","class SqueezeExcitationBlock(keras.layers.Layer):\n","    \"\"\"\n","    Squeeze-and-Excitation (SE) Block.\n","\n","    Learns channel-wise attention weights:\n","    1. Squeeze: Global average pooling (H,W,C) -> (1,1,C)\n","    2. Excitation: FC -> ReLU -> FC -> Sigmoid\n","    3. Scale: Multiply input by attention weights\n","    \"\"\"\n","\n","    def __init__(self, reduction_ratio=16, **kwargs):\n","        super().__init__(**kwargs)\n","        self.reduction_ratio = reduction_ratio\n","\n","    def build(self, input_shape):\n","        channels = input_shape[-1]\n","        reduced_channels = max(channels // self.reduction_ratio, 1)\n","\n","        self.fc1 = layers.Dense(reduced_channels, activation='relu')\n","        self.fc2 = layers.Dense(channels, activation='sigmoid')\n","\n","        super().build(input_shape)\n","\n","    def call(self, inputs):\n","        # Squeeze: Global Average Pooling\n","        squeezed = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)  # (B, 1, 1, C)\n","\n","        # Excitation\n","        x = tf.reshape(squeezed, (tf.shape(inputs)[0], -1))  # (B, C)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = tf.reshape(x, (tf.shape(inputs)[0], 1, 1, -1))  # (B, 1, 1, C)\n","\n","        # Scale\n","        return inputs * x\n","\n","# Test\n","se_block = SqueezeExcitationBlock(reduction_ratio=16)\n","x = tf.random.normal((2, 28, 28, 64))\n","y = se_block(x)\n","\n","print(f\"\\nSqueezeExcitationBlock(reduction_ratio=16)\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"\\n SE learns which channels are important for the task\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcm-_VhvWcDA","executionInfo":{"status":"ok","timestamp":1771138695928,"user_tz":480,"elapsed":64,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"f68fae29-64fa-400f-8fef-1dc21034aedf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","         SQUEEZE-AND-EXCITATION BLOCK\n","============================================================\n","\n","SqueezeExcitationBlock(reduction_ratio=16)\n","Input shape:  (2, 28, 28, 64)\n","Output shape: (2, 28, 28, 64)\n","\n"," SE learns which channels are important for the task\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    TRANSFORMER ENCODER BLOCK\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"          TRANSFORMER ENCODER BLOCK\")\n","print(\"=\"*60)\n","\n","class TransformerEncoderBlock(keras.layers.Layer):\n","    \"\"\"\n","    Transformer Encoder Block.\n","\n","    Architecture:\n","        x -> LayerNorm -> MultiHeadAttention -> + (residual) ->\n","             LayerNorm -> FeedForward -> + (residual) -> output\n","    \"\"\"\n","\n","    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.ff_dim = ff_dim\n","\n","        # Multi-head attention\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads,\n","            key_dim=embed_dim // num_heads\n","        )\n","\n","        # Feed-forward network\n","        self.ffn = Sequential([\n","            layers.Dense(ff_dim, activation='gelu'),\n","            layers.Dropout(dropout_rate),\n","            layers.Dense(embed_dim),\n","            layers.Dropout(dropout_rate)\n","        ])\n","\n","        # Layer normalization\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","\n","        # Dropout\n","        self.dropout1 = layers.Dropout(dropout_rate)\n","\n","    def call(self, inputs, training=False, mask=None):\n","        # Pre-norm architecture (more stable)\n","        # Attention block\n","        x = self.layernorm1(inputs)\n","        attn_output = self.attention(x, x, attention_mask=mask, training=training)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        x = inputs + attn_output  # Residual connection\n","\n","        # Feed-forward block\n","        ffn_input = self.layernorm2(x)\n","        ffn_output = self.ffn(ffn_input, training=training)\n","\n","        return x + ffn_output  # Residual connection\n","\n","# Test\n","transformer_block = TransformerEncoderBlock(\n","    embed_dim=64,\n","    num_heads=4,\n","    ff_dim=256,\n","    dropout_rate=0.1\n",")\n","\n","x = tf.random.normal((2, 20, 64))  # (batch, seq_len, embed_dim)\n","y = transformer_block(x)\n","\n","print(f\"\\nTransformerEncoderBlock(embed_dim=64, num_heads=4, ff_dim=256)\")\n","print(f\"Input shape:  {x.shape}\")\n","print(f\"Output shape: {y.shape}\")\n","print(f\"Parameters:   {sum(np.prod(v.shape) for v in transformer_block.trainable_variables):,}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1I-38YHnWcDA","executionInfo":{"status":"ok","timestamp":1771138696333,"user_tz":480,"elapsed":368,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"6e84d01c-cf2c-42da-9af9-8d3d981d9359"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","          TRANSFORMER ENCODER BLOCK\n","============================================================\n","\n","TransformerEncoderBlock(embed_dim=64, num_heads=4, ff_dim=256)\n","Input shape:  (2, 20, 64)\n","Output shape: (2, 20, 64)\n","Parameters:   49,984\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# Part VI: Custom Training Loops\n","\n","## Full Control with GradientTape\n","\n","While `model.fit()` is convenient, custom training loops give you:\n","\n","- **Complete control** over the training process\n","- **Custom metrics** and logging\n","- **Complex training schemes** (GANs, reinforcement learning)\n","- **Gradient manipulation** (clipping, accumulation)\n","- **Multi-GPU/TPU** strategies"],"metadata":{"id":"z13eQIQpWcDA"}},{"cell_type":"code","source":["# ============================================================================\n","#                    BASIC CUSTOM TRAINING LOOP\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"          BASIC CUSTOM TRAINING LOOP\")\n","print(\"=\"*60)\n","\n","def custom_training_loop(model, train_data, val_data, epochs, learning_rate=0.001):\n","    \"\"\"\n","    Complete custom training loop with GradientTape.\n","    \"\"\"\n","    optimizer = keras.optimizers.Adam(learning_rate)\n","    loss_fn = keras.losses.SparseCategoricalCrossentropy()\n","\n","    # Metrics\n","    train_loss = keras.metrics.Mean()\n","    train_acc = keras.metrics.SparseCategoricalAccuracy()\n","    val_loss = keras.metrics.Mean()\n","    val_acc = keras.metrics.SparseCategoricalAccuracy()\n","\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    for epoch in range(epochs):\n","        # Reset metrics\n","        train_loss.reset_state()\n","        train_acc.reset_state()\n","\n","        # Training loop\n","        for x_batch, y_batch in train_data:\n","            with tf.GradientTape() as tape:\n","                # Forward pass\n","                predictions = model(x_batch, training=True)\n","                loss = loss_fn(y_batch, predictions)\n","\n","            # Backward pass\n","            gradients = tape.gradient(loss, model.trainable_variables)\n","\n","            # Update weights\n","            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","            # Update metrics\n","            train_loss.update_state(loss)\n","            train_acc.update_state(y_batch, predictions)\n","\n","        # Validation loop\n","        val_loss.reset_state()\n","        val_acc.reset_state()\n","\n","        for x_batch, y_batch in val_data:\n","            predictions = model(x_batch, training=False)\n","            loss = loss_fn(y_batch, predictions)\n","            val_loss.update_state(loss)\n","            val_acc.update_state(y_batch, predictions)\n","\n","        # Record history\n","        history['train_loss'].append(train_loss.result().numpy())\n","        history['train_acc'].append(train_acc.result().numpy())\n","        history['val_loss'].append(val_loss.result().numpy())\n","        history['val_acc'].append(val_acc.result().numpy())\n","\n","        # Print progress\n","        print(f\"Epoch {epoch+1}/{epochs} | \"\n","              f\"Train Loss: {train_loss.result():.4f} | \"\n","              f\"Train Acc: {train_acc.result():.4f} | \"\n","              f\"Val Loss: {val_loss.result():.4f} | \"\n","              f\"Val Acc: {val_acc.result():.4f}\")\n","\n","    return history\n","\n","print(\"\\nCustom training loop template created!\")\n","print(\"Key components:\")\n","print(\"  1. GradientTape for computing gradients\")\n","print(\"  2. optimizer.apply_gradients() for weight updates\")\n","print(\"  3. Metrics for tracking performance\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0S7sZ5woWcDA","executionInfo":{"status":"ok","timestamp":1771138696358,"user_tz":480,"elapsed":21,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"b86e8dc1-b83d-48b4-c313-42f10e2b2d1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","          BASIC CUSTOM TRAINING LOOP\n","============================================================\n","\n","Custom training loop template created!\n","Key components:\n","  1. GradientTape for computing gradients\n","  2. optimizer.apply_gradients() for weight updates\n","  3. Metrics for tracking performance\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    TRAINING WITH GRADIENT CLIPPING\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"        TRAINING WITH GRADIENT CLIPPING\")\n","print(\"=\"*60)\n","\n","@tf.function\n","def train_step_with_clipping(model, x, y, optimizer, loss_fn, clip_norm=1.0):\n","    \"\"\"\n","    Single training step with gradient clipping.\n","\n","    Gradient clipping prevents exploding gradients in deep networks.\n","    \"\"\"\n","    with tf.GradientTape() as tape:\n","        predictions = model(x, training=True)\n","        loss = loss_fn(y, predictions)\n","\n","    # Compute gradients\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","\n","    # Clip gradients by global norm\n","    gradients, global_norm = tf.clip_by_global_norm(gradients, clip_norm)\n","\n","    # Apply clipped gradients\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    return loss, global_norm\n","\n","print(\"Gradient Clipping Options:\")\n","print(\"  - tf.clip_by_value(g, -clip, clip)  : Clip element-wise\")\n","print(\"  - tf.clip_by_norm(g, clip)          : Clip each tensor by L2 norm\")\n","print(\"  - tf.clip_by_global_norm(grads, clip): Clip all gradients together\")\n","print(\"\\nGlobal norm is most common - maintains gradient direction!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nt4KslvnWcDA","executionInfo":{"status":"ok","timestamp":1771138696402,"user_tz":480,"elapsed":41,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"b35242ae-8cfa-4906-fbb6-356a7939d84b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","        TRAINING WITH GRADIENT CLIPPING\n","============================================================\n","Gradient Clipping Options:\n","  - tf.clip_by_value(g, -clip, clip)  : Clip element-wise\n","  - tf.clip_by_norm(g, clip)          : Clip each tensor by L2 norm\n","  - tf.clip_by_global_norm(grads, clip): Clip all gradients together\n","\n","Global norm is most common - maintains gradient direction!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    CUSTOM MODEL WITH train_step()\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"        CUSTOM MODEL WITH train_step()\")\n","print(\"=\"*60)\n","\n","class CustomTrainableModel(keras.Model):\n","    \"\"\"\n","    Model with custom training logic built-in.\n","\n","    Override train_step() to customize what happens in model.fit().\n","    This is the best of both worlds:\n","    - Custom training logic\n","    - Still use model.fit() with callbacks, validation, etc.\n","    \"\"\"\n","\n","    def __init__(self, units_list, num_classes, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.dense_layers = []\n","        for units in units_list:\n","            self.dense_layers.append(layers.Dense(units, activation='relu'))\n","            self.dense_layers.append(layers.Dropout(0.2))\n","\n","        self.output_layer = layers.Dense(num_classes, activation='softmax')\n","\n","        # Custom metrics\n","        self.loss_tracker = keras.metrics.Mean(name='loss')\n","        self.acc_tracker = keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","\n","    def call(self, inputs, training=False):\n","        x = inputs\n","        for layer in self.dense_layers:\n","            x = layer(x, training=training)\n","        return self.output_layer(x)\n","\n","    def train_step(self, data):\n","        \"\"\"\n","        Custom training step.\n","        Called by model.fit() for each batch.\n","        \"\"\"\n","        x, y = data\n","\n","        with tf.GradientTape() as tape:\n","            y_pred = self(x, training=True)\n","            loss = keras.losses.sparse_categorical_crossentropy(y, y_pred)\n","            loss = tf.reduce_mean(loss)\n","\n","        # Compute and apply gradients\n","        gradients = tape.gradient(loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n","\n","        # Update metrics\n","        self.loss_tracker.update_state(loss)\n","        self.acc_tracker.update_state(y, y_pred)\n","\n","        return {\n","            'loss': self.loss_tracker.result(),\n","            'accuracy': self.acc_tracker.result()\n","        }\n","\n","    def test_step(self, data):\n","        \"\"\"Custom evaluation step.\"\"\"\n","        x, y = data\n","        y_pred = self(x, training=False)\n","        loss = keras.losses.sparse_categorical_crossentropy(y, y_pred)\n","\n","        self.loss_tracker.update_state(tf.reduce_mean(loss))\n","        self.acc_tracker.update_state(y, y_pred)\n","\n","        return {\n","            'loss': self.loss_tracker.result(),\n","            'accuracy': self.acc_tracker.result()\n","        }\n","\n","    @property\n","    def metrics(self):\n","        return [self.loss_tracker, self.acc_tracker]\n","\n","# Test\n","custom_model = CustomTrainableModel([64, 32], num_classes=10)\n","custom_model.compile(optimizer='adam')\n","\n","print(\"\\nCustom model with train_step() created!\")\n","print(\"Now model.fit() uses our custom training logic\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ocCaxVeWcDA","executionInfo":{"status":"ok","timestamp":1771138696553,"user_tz":480,"elapsed":156,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"c4e33fa6-a91f-4f9a-f0f8-3c6a21f0679c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","        CUSTOM MODEL WITH train_step()\n","============================================================\n","\n","Custom model with train_step() created!\n","Now model.fit() uses our custom training logic\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# Part VII: Practical Demos\n","\n","## Putting It All Together\n","\n","Let's combine everything we've learned in real examples."],"metadata":{"id":"S6cCw5HyWcDA"}},{"cell_type":"code","source":["# ============================================================================\n","#              DEMO 1: CUSTOM RESNET FOR DIGIT CLASSIFICATION\n","# ============================================================================\n","\n","print(\"=\"*60)\n","print(\"     DEMO: CUSTOM RESNET FOR DIGIT CLASSIFICATION\")\n","print(\"=\"*60)\n","\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load digits dataset\n","digits = load_digits()\n","X, y = digits.data, digits.target\n","\n","# Preprocess\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Reshape for CNN: (samples, 8, 8, 1)\n","X = X.reshape(-1, 8, 8, 1).astype(np.float32)\n","\n","# Split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"Training samples: {X_train.shape[0]}\")\n","print(f\"Test samples:     {X_test.shape[0]}\")\n","print(f\"Image shape:      {X_train.shape[1:]}\")\n","\n","# Build custom ResNet model\n","class MiniResNet(keras.Model):\n","    \"\"\"Mini ResNet with custom residual blocks.\"\"\"\n","\n","    def __init__(self, num_classes=10):\n","        super().__init__()\n","\n","        # Initial convolution\n","        self.conv1 = layers.Conv2D(32, 3, padding='same', activation='relu')\n","\n","        # Residual blocks\n","        self.res_block1 = ResidualBlock(32)\n","        self.res_block2 = ResidualBlock(64, stride=2)\n","\n","        # SE block for channel attention\n","        self.se_block = SqueezeExcitationBlock(reduction_ratio=8)\n","\n","        # Classification head\n","        self.global_pool = layers.GlobalAveragePooling2D()\n","        self.dropout = layers.Dropout(0.3)\n","        self.dense = layers.Dense(num_classes, activation='softmax')\n","\n","    def call(self, x, training=False):\n","        x = self.conv1(x)\n","        x = self.res_block1(x, training=training)\n","        x = self.res_block2(x, training=training)\n","        x = self.se_block(x)\n","        x = self.global_pool(x)\n","        x = self.dropout(x, training=training)\n","        return self.dense(x)\n","\n","# Create and compile\n","tf.random.set_seed(42)\n","resnet_model = MiniResNet(num_classes=10)\n","\n","resnet_model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Build model by calling it\n","_ = resnet_model(X_train[:1])\n","resnet_model.summary()\n","\n","# Train\n","print(\"\\nTraining MiniResNet...\")\n","history = resnet_model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=30,\n","    batch_size=32,\n","    verbose=1\n",")\n","\n","# Evaluate\n","test_loss, test_acc = resnet_model.evaluate(X_test, y_test, verbose=0)\n","print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hJng8MQqWcDA","executionInfo":{"status":"ok","timestamp":1771138741079,"user_tz":480,"elapsed":44579,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"07ff4c2f-0337-451a-ba54-5c6e1fd69fb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","     DEMO: CUSTOM RESNET FOR DIGIT CLASSIFICATION\n","============================================================\n","Training samples: 1437\n","Test samples:     360\n","Image shape:      (8, 8, 1)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"mini_res_net\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mini_res_net\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n","\n"," conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m320\u001b[0m \n","\n"," residual_block_2                 ?                              \u001b[38;5;34m18,688\u001b[0m \n"," (\u001b[38;5;33mResidualBlock\u001b[0m)                                                        \n","\n"," residual_block_3                 ?                              \u001b[38;5;34m58,112\u001b[0m \n"," (\u001b[38;5;33mResidualBlock\u001b[0m)                                                        \n","\n"," squeeze_excitation_block_1       ?                               \u001b[38;5;34m1,096\u001b[0m \n"," (\u001b[38;5;33mSqueezeExcitationBlock\u001b[0m)                                               \n","\n"," global_average_pooling2d         ?                                   \u001b[38;5;34m0\u001b[0m \n"," (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n","\n"," dropout_6 (\u001b[38;5;33mDropout\u001b[0m)              ?                                   \u001b[38;5;34m0\u001b[0m \n","\n"," dense_8 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)                           \u001b[38;5;34m650\u001b[0m \n","\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n","\n"," conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n","\n"," residual_block_2                 ?                              <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                                                        \n","\n"," residual_block_3                 ?                              <span style=\"color: #00af00; text-decoration-color: #00af00\">58,112</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResidualBlock</span>)                                                        \n","\n"," squeeze_excitation_block_1       ?                               <span style=\"color: #00af00; text-decoration-color: #00af00\">1,096</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SqueezeExcitationBlock</span>)                                               \n","\n"," global_average_pooling2d         ?                                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n","\n"," dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              ?                                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n","\n"," dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> \n","\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,866\u001b[0m (308.07 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,866</span> (308.07 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,354\u001b[0m (306.07 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,354</span> (306.07 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Training MiniResNet...\n","Epoch 1/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.3395 - loss: 2.0288 - val_accuracy: 0.4778 - val_loss: 2.1699\n","Epoch 2/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8907 - loss: 0.7920 - val_accuracy: 0.1833 - val_loss: 2.0316\n","Epoch 3/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9626 - loss: 0.2990 - val_accuracy: 0.1861 - val_loss: 2.1517\n","Epoch 4/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9835 - loss: 0.1319 - val_accuracy: 0.4389 - val_loss: 1.6141\n","Epoch 5/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9880 - loss: 0.0806 - val_accuracy: 0.4750 - val_loss: 1.5320\n","Epoch 6/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9938 - loss: 0.0554 - val_accuracy: 0.7028 - val_loss: 0.7829\n","Epoch 7/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0328 - val_accuracy: 0.8361 - val_loss: 0.4287\n","Epoch 8/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0251 - val_accuracy: 0.8944 - val_loss: 0.2916\n","Epoch 9/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.0182 - val_accuracy: 0.9750 - val_loss: 0.1069\n","Epoch 10/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9995 - loss: 0.0156 - val_accuracy: 0.9861 - val_loss: 0.0795\n","Epoch 11/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9991 - loss: 0.0179 - val_accuracy: 0.9833 - val_loss: 0.0577\n","Epoch 12/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9833 - val_loss: 0.0580\n","Epoch 13/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9981 - loss: 0.0149 - val_accuracy: 0.9750 - val_loss: 0.0756\n","Epoch 14/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9983 - loss: 0.0222 - val_accuracy: 0.9833 - val_loss: 0.0483\n","Epoch 15/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9990 - loss: 0.0134 - val_accuracy: 0.9889 - val_loss: 0.0355\n","Epoch 16/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9972 - val_loss: 0.0176\n","Epoch 17/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9944 - val_loss: 0.0235\n","Epoch 18/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9917 - val_loss: 0.0209\n","Epoch 19/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9917 - val_loss: 0.0226\n","Epoch 20/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9917 - val_loss: 0.0261\n","Epoch 21/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9944 - val_loss: 0.0170\n","Epoch 22/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9917 - val_loss: 0.0251\n","Epoch 23/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9944 - val_loss: 0.0265\n","Epoch 24/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9944 - val_loss: 0.0263\n","Epoch 25/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9944 - val_loss: 0.0229\n","Epoch 26/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9917 - val_loss: 0.0266\n","Epoch 27/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9944 - val_loss: 0.0213\n","Epoch 28/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9944 - val_loss: 0.0207\n","Epoch 29/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9972 - val_loss: 0.0191\n","Epoch 30/30\n","\u001b[1m45/45\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9972 - val_loss: 0.0248\n","\n","Test Accuracy: 99.72%\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#                    VISUALIZE TRAINING RESULTS\n","# ============================================================================\n","\n","# Plot training history\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n","\n","ax1.plot(history.history['loss'], 'b-', label='Train Loss')\n","ax1.plot(history.history['val_loss'], 'r-', label='Val Loss')\n","ax1.set_xlabel('Epoch')\n","ax1.set_ylabel('Loss')\n","ax1.set_title('MiniResNet Training Loss', fontweight='bold')\n","ax1.legend()\n","ax1.grid(True, alpha=0.3)\n","\n","ax2.plot(history.history['accuracy'], 'b-', label='Train Acc')\n","ax2.plot(history.history['val_accuracy'], 'r-', label='Val Acc')\n","ax2.set_xlabel('Epoch')\n","ax2.set_ylabel('Accuracy')\n","ax2.set_title('MiniResNet Training Accuracy', fontweight='bold')\n","ax2.legend()\n","ax2.grid(True, alpha=0.3)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Visualize predictions\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n","fig.suptitle('MiniResNet Predictions', fontsize=14, fontweight='bold')\n","\n","predictions = resnet_model.predict(X_test[:10], verbose=0)\n","pred_classes = np.argmax(predictions, axis=1)\n","\n","for i, ax in enumerate(axes.flatten()):\n","    img = X_test[i].reshape(8, 8)\n","    true_label = y_test[i]\n","    pred_label = pred_classes[i]\n","    confidence = predictions[i][pred_label] * 100\n","\n","    ax.imshow(img, cmap='gray')\n","    color = 'green' if true_label == pred_label else 'red'\n","    ax.set_title(f'True: {true_label}, Pred: {pred_label}\\n({confidence:.1f}%)',\n","                 color=color, fontsize=10)\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":951},"id":"6QkXz-l8WcDA","executionInfo":{"status":"ok","timestamp":1771138742560,"user_tz":480,"elapsed":1454,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"f17b61d4-db1f-469d-ef4b-d4aea64cdaaf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1400x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x600 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# ============================================================================\n","#                         ADVANCED CHEAT SHEET\n","# ============================================================================\n","\n","print(\"=\"*70)\n","print(\"              ADVANCED TENSORFLOW/KERAS CHEAT SHEET\")\n","print(\"=\"*70)\n","\n","cheat_sheet = \"\"\"\n","GRADIENTTAPE PATTERNS\n","---------------------\n","# Basic gradient\n","with tf.GradientTape() as tape:\n","    y = model(x)\n","grads = tape.gradient(y, model.trainable_variables)\n","\n","# Higher-order derivatives (nested tapes)\n","with tf.GradientTape() as t2:\n","    with tf.GradientTape() as t1:\n","        y = f(x)\n","    dy = t1.gradient(y, x)\n","d2y = t2.gradient(dy, x)\n","\n","# Jacobian\n","jacobian = tape.jacobian(y, x)\n","\n","# Custom gradient\n","@tf.custom_gradient\n","def custom_op(x):\n","    def grad(dy):\n","        return dy * custom_backward\n","    return forward_result, grad\n","\n","CUSTOM KERAS LAYERS\n","-------------------\n","class CustomLayer(keras.layers.Layer):\n","    def __init__(self, units, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.kernel = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer='glorot_uniform',\n","            trainable=True\n","        )\n","        super().build(input_shape)\n","\n","    def call(self, inputs, training=False):\n","        return inputs @ self.kernel\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['units'] = self.units\n","        return config\n","\n","CUSTOM TRAINING\n","---------------\n","# Override train_step for model.fit()\n","class CustomModel(keras.Model):\n","    def train_step(self, data):\n","        x, y = data\n","        with tf.GradientTape() as tape:\n","            y_pred = self(x, training=True)\n","            loss = self.compute_loss(y=y, y_pred=y_pred)\n","        grads = tape.gradient(loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n","        return {'loss': loss}\n","\n","GRADIENT MANIPULATION\n","---------------------\n","# Clip by global norm\n","grads, _ = tf.clip_by_global_norm(grads, max_norm=1.0)\n","\n","# Gradient accumulation\n","accumulated = [acc + g/steps for acc, g in zip(accumulated, grads)]\n","\"\"\"\n","print(cheat_sheet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5Z_iXlFWcDA","executionInfo":{"status":"ok","timestamp":1771138742576,"user_tz":480,"elapsed":11,"user":{"displayName":"Prachi Gupta","userId":"18051866031221426127"}},"outputId":"68795c88-7bc1-49a7-97d5-025759edc341"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","              ADVANCED TENSORFLOW/KERAS CHEAT SHEET\n","======================================================================\n","\n","GRADIENTTAPE PATTERNS\n","---------------------\n","# Basic gradient\n","with tf.GradientTape() as tape:\n","    y = model(x)\n","grads = tape.gradient(y, model.trainable_variables)\n","\n","# Higher-order derivatives (nested tapes)\n","with tf.GradientTape() as t2:\n","    with tf.GradientTape() as t1:\n","        y = f(x)\n","    dy = t1.gradient(y, x)\n","d2y = t2.gradient(dy, x)\n","\n","# Jacobian\n","jacobian = tape.jacobian(y, x)\n","\n","# Custom gradient\n","@tf.custom_gradient\n","def custom_op(x):\n","    def grad(dy):\n","        return dy * custom_backward\n","    return forward_result, grad\n","\n","CUSTOM KERAS LAYERS\n","-------------------\n","class CustomLayer(keras.layers.Layer):\n","    def __init__(self, units, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.kernel = self.add_weight(\n","            shape=(input_shape[-1], self.units),\n","            initializer='glorot_uniform',\n","            trainable=True\n","        )\n","        super().build(input_shape)\n","\n","    def call(self, inputs, training=False):\n","        return inputs @ self.kernel\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['units'] = self.units\n","        return config\n","\n","CUSTOM TRAINING\n","---------------\n","# Override train_step for model.fit()\n","class CustomModel(keras.Model):\n","    def train_step(self, data):\n","        x, y = data\n","        with tf.GradientTape() as tape:\n","            y_pred = self(x, training=True)\n","            loss = self.compute_loss(y=y, y_pred=y_pred)\n","        grads = tape.gradient(loss, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n","        return {'loss': loss}\n","\n","GRADIENT MANIPULATION\n","---------------------\n","# Clip by global norm\n","grads, _ = tf.clip_by_global_norm(grads, max_norm=1.0)\n","\n","# Gradient accumulation\n","accumulated = [acc + g/steps for acc, g in zip(accumulated, grads)]\n","\n"]}]},{"cell_type":"markdown","source":["---\n","\n","# Conclusion\n","\n","## Your Advanced TensorFlow & Keras Journey\n","\n","Congratulations! You've mastered advanced TensorFlow and Keras techniques.\n","\n","### What You Learned\n","\n","| Part | Topic | Key Takeaway |\n","|------|-------|-------------|\n","| I | Advanced GradientTape | Nested tapes, Jacobians, custom gradients |\n","| II | Building Ops | Conv, pooling, normalization from scratch |\n","| III | Primitive Layers | Dense, Conv2D with only tf.Variable |\n","| IV | Custom Keras Layers | Proper subclassing with build() and call() |\n","| V | Advanced Architectures | ResNet, SE-Net, Transformer blocks |\n","| VI | Custom Training | Full control with GradientTape |\n","| VII | Practical Demos | Real-world model combining everything |\n","\n","### When to Use What\n","\n","| Approach | Use When |\n","|----------|----------|\n","| `model.fit()` | Standard training, quick prototyping |\n","| Custom `train_step()` | Custom logic but want callbacks/validation |\n","| Full GradientTape loop | GANs, RL, complex multi-model training |\n","| Custom layers | Reusable components, research |\n","| Primitive layers | Learning, debugging, maximum control |\n","\n","### The Complete Learning Path\n","\n","1. **NumPy from Scratch** - Understand the math deeply\n","2. **PyTorch** - Research-friendly framework\n","3. **TensorFlow/Keras Part 1** - Fundamentals and high-level API\n","4. **TensorFlow/Keras Part 2** - Advanced custom components (This notebook!)\n","\n","### Next Steps\n","\n","- **Vision Transformers (ViT)** - Transformers for images\n","- **Diffusion Models** - State-of-the-art generative AI\n","- **Neural Architecture Search** - Automated model design\n","- **Quantization & Pruning** - Model optimization for deployment\n","- **TensorFlow Extended (TFX)** - Production ML pipelines\n","\n","---\n","\n","*\"The more you understand the primitives, the better you can innovate.\"*\n","\n","**Happy Deep Learning!**"],"metadata":{"id":"wQs6OOHGWcDA"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"colab":{"provenance":[{"file_id":"1J6fxzA-OLGYFczad68QsTPNoyJClNFi8","timestamp":1771105929035}]}},"nbformat":4,"nbformat_minor":0}
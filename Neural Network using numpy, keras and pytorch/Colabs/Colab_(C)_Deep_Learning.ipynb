{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMA9fsfXtAVwE4dK0wXfUMv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prachii26/DeepLearningCMPE258/blob/main/Neural%20Network%20using%20numpy%2C%20keras%20and%20pytorch/Colabs/Colab_(C)_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sxYUxCYwejK",
        "outputId": "6fb1c028-d96c-441f-e4d6-1cbf2c6891c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "PyTorch version: 2.9.0+cpu\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import libraries and set up device\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Generate synthetic dataset and train/test split\n",
        "\n",
        "# Generate synthetic data: y = sin(x1) * x2^2 + cos(x2) * x1 + 0.5 * x3\n",
        "n_samples = 1000\n",
        "\n",
        "x1 = np.random.uniform(-2, 2, n_samples)\n",
        "x2 = np.random.uniform(-2, 2, n_samples)\n",
        "x3 = np.random.uniform(-2, 2, n_samples)\n",
        "\n",
        "X = np.column_stack([x1, x2, x3])\n",
        "y = (np.sin(x1) * x2**2 + np.cos(x2) * x1 + 0.5 * x3).reshape(-1, 1)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# Train/test split (80/20)\n",
        "split_idx = int(0.8 * n_samples)\n",
        "X_train, X_test = X_tensor[:split_idx], X_tensor[split_idx:]\n",
        "y_train, y_test = y_tensor[:split_idx], y_tensor[split_idx:]\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89B0KCUpxM1H",
        "outputId": "020d6e8d-7547-40c2-9272-8bd5350429f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: torch.Size([800, 3]), torch.Size([800, 1])\n",
            "Test set: torch.Size([200, 3]), torch.Size([200, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Create DataLoader for batched training\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "print(f\"Batch size: {batch_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g1YsmfnxRfs",
        "outputId": "0c77837c-b40d-4675-a7d7-34b843217027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 25\n",
            "Test batches: 7\n",
            "Batch size: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Define the 3-layer neural network class\n",
        "\n",
        "class ThreeLayerNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
        "        super(ThreeLayerNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
        "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "        self.fc3 = nn.Linear(hidden2_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.tanh(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "print(\"3-layer neural network class defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMSO66cOxj8X",
        "outputId": "06ad1f06-d2c5-4cd1-d463-9f132794a8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-layer neural network class defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Instantiate model, loss function, and optimizer\n",
        "\n",
        "# Network architecture\n",
        "input_size = 3\n",
        "hidden1_size = 10\n",
        "hidden2_size = 8\n",
        "output_size = 1\n",
        "\n",
        "# Create model and move to device\n",
        "model = ThreeLayerNet(input_size, hidden1_size, hidden2_size, output_size).to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(f\"Model: {model}\")\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")\n",
        "print(f\"Loss function: MSE\")\n",
        "print(f\"Optimizer: Adam with lr={learning_rate}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uh5uhC5xpkW",
        "outputId": "9e039391-09ae-4fe8-862d-a84b08e4216c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: ThreeLayerNet(\n",
            "  (fc1): Linear(in_features=3, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=10, out_features=8, bias=True)\n",
            "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (tanh): Tanh()\n",
            ")\n",
            "\n",
            "Total parameters: 137\n",
            "Loss function: MSE\n",
            "Optimizer: Adam with lr=0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Training loop with progress printing\n",
        "\n",
        "epochs = 100\n",
        "print_every = 20\n",
        "\n",
        "train_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(batch_X)\n",
        "        loss = criterion(predictions, batch_y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Average loss for the epoch\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    if (epoch + 1) % print_every == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] - Loss: {avg_loss:.6f}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clzh7egLxurr",
        "outputId": "31b807b9-8e05-4ddf-f951-d25c4b985c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch [20/100] - Loss: 0.046015\n",
            "Epoch [40/100] - Loss: 0.022165\n",
            "Epoch [60/100] - Loss: 0.015185\n",
            "Epoch [80/100] - Loss: 0.011977\n",
            "Epoch [100/100] - Loss: 0.009108\n",
            "--------------------------------------------------\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Evaluate on test set and print summary\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        loss = criterion(predictions, batch_y)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        all_predictions.append(predictions.cpu())\n",
        "        all_targets.append(batch_y.cpu())\n",
        "\n",
        "# Calculate average test loss\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "\n",
        "# Concatenate all predictions and targets\n",
        "all_predictions = torch.cat(all_predictions)\n",
        "all_targets = torch.cat(all_targets)\n",
        "\n",
        "# Calculate RÂ² score\n",
        "ss_res = torch.sum((all_targets - all_predictions) ** 2)\n",
        "ss_tot = torch.sum((all_targets - torch.mean(all_targets)) ** 2)\n",
        "r2_score = 1 - (ss_res / ss_tot)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"EVALUATION SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Final Training Loss: {train_losses[-1]:.6f}\")\n",
        "print(f\"Test Loss: {avg_test_loss:.6f}\")\n",
        "print(f\"Test RÂ² Score: {r2_score.item():.4f}\")\n",
        "print(f\"Test MAE: {torch.mean(torch.abs(all_targets - all_predictions)).item():.4f}\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FetjVdw5xxe6",
        "outputId": "fd491e5b-9554-442f-b812-8c058f05f28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "EVALUATION SUMMARY\n",
            "==================================================\n",
            "Final Training Loss: 0.009108\n",
            "Test Loss: 0.011476\n",
            "Test RÂ² Score: 0.9963\n",
            "Test MAE: 0.0778\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Final summary and completion report\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\" \" * 10 + \"PYTORCH CLASS-BASED IMPLEMENTATION COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nâœ… ASSIGNMENT REQUIREMENTS - ALL COMPLETED:\")\n",
        "print(\"-\" * 70)\n",
        "print(\"âœ“ Used torch.nn.Module for model definition\")\n",
        "print(\"âœ“ Used torch.nn.Linear for layers\")\n",
        "print(\"âœ“ Used torch.optim.Adam for optimizer\")\n",
        "print(\"âœ“ Used torch.nn.MSELoss for loss function\")\n",
        "print(\"âœ“ Used TensorDataset and DataLoader for batching\")\n",
        "print(\"âœ“ Used autograd (loss.backward() and optimizer.step())\")\n",
        "print(\"âœ“ 3-layer architecture: 3 inputs â†’ 2 hidden â†’ 1 output\")\n",
        "print(\"âœ“ Non-linear regression with MSE loss\")\n",
        "\n",
        "print(\"\\nðŸ§  MODEL ARCHITECTURE:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Input Layer:      {input_size} features\")\n",
        "print(f\"Hidden Layer 1:   {hidden1_size} neurons (ReLU)\")\n",
        "print(f\"Hidden Layer 2:   {hidden2_size} neurons (Tanh)\")\n",
        "print(f\"Output Layer:     {output_size} neuron (Linear)\")\n",
        "print(f\"Total Parameters: {sum(p.numel() for p in model.parameters())}\")\n",
        "\n",
        "print(\"\\nðŸ“Š TRAINING CONFIGURATION:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Dataset Size:     {n_samples} samples (train: {len(X_train)}, test: {len(X_test)})\")\n",
        "print(f\"Batch Size:       {batch_size}\")\n",
        "print(f\"Epochs:           {epochs}\")\n",
        "print(f\"Learning Rate:    {learning_rate}\")\n",
        "print(f\"Optimizer:        Adam\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ FINAL RESULTS:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Training Loss:    {train_losses[-1]:.6f}\")\n",
        "print(f\"Test Loss:        {avg_test_loss:.6f}\")\n",
        "print(f\"Test RÂ² Score:    {r2_score.item():.4f}\")\n",
        "print(f\"Test MAE:         {torch.mean(torch.abs(all_targets - all_predictions)).item():.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\" \" * 20 + \"ðŸŽ‰ ALL TASKS COMPLETED!\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzAPge8-x7Xt",
        "outputId": "4bd01f1d-0f8f-4c80-ce1f-c0bb049e37e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "          PYTORCH CLASS-BASED IMPLEMENTATION COMPLETE\n",
            "======================================================================\n",
            "\n",
            "âœ… ASSIGNMENT REQUIREMENTS - ALL COMPLETED:\n",
            "----------------------------------------------------------------------\n",
            "âœ“ Used torch.nn.Module for model definition\n",
            "âœ“ Used torch.nn.Linear for layers\n",
            "âœ“ Used torch.optim.Adam for optimizer\n",
            "âœ“ Used torch.nn.MSELoss for loss function\n",
            "âœ“ Used TensorDataset and DataLoader for batching\n",
            "âœ“ Used autograd (loss.backward() and optimizer.step())\n",
            "âœ“ 3-layer architecture: 3 inputs â†’ 2 hidden â†’ 1 output\n",
            "âœ“ Non-linear regression with MSE loss\n",
            "\n",
            "ðŸ§  MODEL ARCHITECTURE:\n",
            "----------------------------------------------------------------------\n",
            "Input Layer:      3 features\n",
            "Hidden Layer 1:   10 neurons (ReLU)\n",
            "Hidden Layer 2:   8 neurons (Tanh)\n",
            "Output Layer:     1 neuron (Linear)\n",
            "Total Parameters: 137\n",
            "\n",
            "ðŸ“Š TRAINING CONFIGURATION:\n",
            "----------------------------------------------------------------------\n",
            "Dataset Size:     1000 samples (train: 800, test: 200)\n",
            "Batch Size:       32\n",
            "Epochs:           100\n",
            "Learning Rate:    0.01\n",
            "Optimizer:        Adam\n",
            "\n",
            "ðŸŽ¯ FINAL RESULTS:\n",
            "----------------------------------------------------------------------\n",
            "Training Loss:    0.009108\n",
            "Test Loss:        0.011476\n",
            "Test RÂ² Score:    0.9963\n",
            "Test MAE:         0.0778\n",
            "\n",
            "======================================================================\n",
            "                    ðŸŽ‰ ALL TASKS COMPLETED!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTQMdGSqyEZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}